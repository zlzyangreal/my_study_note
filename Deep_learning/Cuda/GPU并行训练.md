# 数据并行
数据并行是指对数据进行划分并将其分配给每个GPU，并使用相同的AI模型进行评估。一旦GPU完成前向传播的过程，他们就会输出梯度或者学习过的参数。由于每个GPU都产生梯度但只需要训练一个模型，因此多个梯度被编译、平均、简化为一个值，最终用于更新模型参数。下一个[epoch](神经网络中的Epoch、Iteration、Batchsize)的训练也如上进行。比较理想的是所有GPU同时完成运算并进行梯度平均，但显然不太现实，有先后就有等待，因此数据并行可以同步或异步完成。
## 同步的数据并行
每个GPU组必须等待所有其余GPU组计算完梯度后才能平均、简化这些梯度并更新模型参数。参数被更新后模型就可以继续计算下一个[epoch](神经网络中的Epoch、Iteration、Batchsize)
## 异步的数据并行
每个GPU组独立训练，无需执行同步的梯度整合。取而代之的是梯度会在计算完成后传回参数服务器。由于每个GPU组不需要等待其余的GPU组完成计算，也不需要计算梯度平均，因此是异步的。异步数据并行在模型的学习阶段需要一个单独的参数服务器，因此成本更高一些。

**[DDP和DP都是数据并行](DDP(显卡交火).md)**
#  **模型并行**
与拆分数据相反，模型并行将模型（或训练模型的工作）拆分到每个GPU上。模型拆分通常是将特定的任务分配给一个处理器或多个处理器，以优化GPU的利用率。模型并行可以被看作一条AI流水线，它创建一个多层的网络，可以应对需要处理大型数据集并且无法使用数据并行的情况

![[并行训练算法.png]]
## Pipeline Parallelism (PP)
![[PP.png]]
例如PipeDream，GPipe，和Chimera
GPipe有[tensorflow版本](GPipe(tensorflow版本).md)和pytorch版本
**不同模型组件在不同的GPU上时，GPU之间的传输就很重要，对于GPU之间的通信是一个考验。但是GPU的通信在这种密集任务中很难办到，所以这个方式慢慢淡出了视野**
